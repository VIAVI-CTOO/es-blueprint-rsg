{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Saving Blueprint - PoC Demo\n",
    "\n",
    "This notebook demonstrates intent-driven energy optimization in 5G networks.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load 24-hour KPI data from CSV (UE and Cell reports)\n",
    "2. Accept operator intent (QoS threshold)\n",
    "3. Generate decisions for each 15-minute interval (96 total)\n",
    "4. Output filtered decision table (Sleep/Wake actions only)\n",
    "5. Execute decisions on RSG simulator at correct timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q pandas sqlalchemy python-dotenv langchain-nvidia-ai-endpoints llama-index-llms-nvidia llama-index-embeddings-nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "NVIDIA_API_KEY = \"\"\n",
    "\n",
    "print(NVIDIA_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent if Path(os.getcwd()).name == \"notebooks\" else Path(os.getcwd())\n",
    "DATA_PATH = str(PROJECT_ROOT / \"data\")\n",
    "CELL_REPORTS = f\"{DATA_PATH}/CellReports.csv\"\n",
    "UE_REPORTS = f\"{DATA_PATH}/UEReports.csv\"\n",
    "\n",
    "TABLE_NAME = \"kpi_data\"\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"meta/llama-3.1-70b-instruct\")\n",
    "\n",
    "# RSG / Scenario configuration\n",
    "RSG_HOST = os.getenv(\"RSG_HOST\", \"3.211.96.252\")  # AWS RSG host\n",
    "USER_NAME = os.getenv(\"RSG_USER_NAME\", os.getenv(\"USER\", \"user1\"))\n",
    "SCENARIO_CONF = os.getenv(\"SCENARIO_CONF\", str(PROJECT_ROOT / \"rsg_config\" / \"config.conf\"))\n",
    "RSG_ADDRESS = os.getenv(\"RSG_ADDRESS\", \"\").strip()  # optional full override (internal RSG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Setup — Install VIAVI ADK from RSG host (wheel)\n",
    "# =============================================================================\n",
    "import os, sys, subprocess\n",
    "\n",
    "RSG_WHEEL_ADDRESS = os.getenv(\"RSG_WHEEL_ADDRESS\", \"http://3.211.96.252:8000\").rstrip(\"/\")\n",
    "ADK_URL = f\"{RSG_WHEEL_ADDRESS}/adk\"\n",
    "\n",
    "# NOTE: Do NOT set RSG_ADDRESS to the base host URL (e.g., http://3.211.96.252:8000).\n",
    "#       RSG_ADDRESS is reserved for the *container* API root like http://<host>:8000/c/<hash>/\n",
    "#       Use RSG_WHEEL_ADDRESS only for ADK wheel installation.\n",
    "# Set to True only when you want to force reinstall/update\n",
    "FORCE_ADK_UPDATE = False\n",
    "\n",
    "def pip_install(args):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *args])\n",
    "\n",
    "def ensure_viavi_adk():\n",
    "    if not FORCE_ADK_UPDATE:\n",
    "        try:\n",
    "            from viavi.rsg import Scenario, Simulation  # noqa: F401\n",
    "            print(\"✓ VIAVI ADK already installed (viavi.rsg import OK)\")\n",
    "            return\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(\"Installing/updating VIAVI ADK from:\", ADK_URL)\n",
    "    pip_install([\"-U\", \"setuptools\", \"packaging\"])\n",
    "    pip_install([\"-U\", ADK_URL])\n",
    "\n",
    "    from viavi.rsg import Scenario, Simulation  # noqa: F401\n",
    "    print(\"✓ VIAVI ADK installed/updated successfully\")\n",
    "\n",
    "ensure_viavi_adk()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UE and Cell reports\n",
    "df_ue = pd.read_csv(UE_REPORTS)\n",
    "df_cell = pd.read_csv(CELL_REPORTS)\n",
    "\n",
    "print(f\"UEReports: {len(df_ue)} rows, {df_ue['Viavi.UE.Name'].nunique()} unique UEs\")\n",
    "print(f\"CellReports: {len(df_cell)} rows, {df_cell['Viavi.Cell.Name'].nunique()} unique cells\")\n",
    "\n",
    "# Filter active UEs (throughput > 0.1 Mbps)\n",
    "ACTIVE_THROUGHPUT_THRESHOLD = 0.1\n",
    "active_ues = df_ue[df_ue['DRB.UEThpDl'] > ACTIVE_THROUGHPUT_THRESHOLD].copy()\n",
    "print(f\"\\nActive UEs (throughput > {ACTIVE_THROUGHPUT_THRESHOLD} Mbps): {active_ues['Viavi.UE.Name'].nunique()} unique\")\n",
    "\n",
    "# Get cell-level PRB from CellReports\n",
    "cell_prb = df_cell[['time (ms)', 'Viavi.Cell.Name', 'RRU.PrbTotDl', 'Viavi.isEnergySaving']].copy()\n",
    "cell_prb = cell_prb.rename(columns={'RRU.PrbTotDl': 'Cell_PRB'})\n",
    "\n",
    "# Get UE-level throughput from active UEs\n",
    "ue_thp = active_ues[['time (ms)', 'Viavi.Cell.Name', 'Viavi.UE.Name', 'DRB.UEThpDl']].copy()\n",
    "ue_thp = ue_thp.rename(columns={'DRB.UEThpDl': 'UE_Throughput'})\n",
    "\n",
    "# Merge UE data with Cell data (join on time and cell)\n",
    "merged_df = ue_thp.merge(cell_prb, on=['time (ms)', 'Viavi.Cell.Name'], how='left')\n",
    "\n",
    "# Parse site and band from cell name (e.g., \"S1/N12/C1\" -> site=\"S1/C1\", band=\"N12\")\n",
    "merged_df['site'] = merged_df['Viavi.Cell.Name'].str.split('/').str[0] + '/' + merged_df['Viavi.Cell.Name'].str.split('/').str[2]\n",
    "merged_df['band'] = merged_df['Viavi.Cell.Name'].str.split('/').str[1]\n",
    "\n",
    "# Rename columns for SQL table\n",
    "df = merged_df.rename(columns={\n",
    "    'time (ms)': 'time',\n",
    "    'Viavi.Cell.Name': 'cell_full',\n",
    "    'Viavi.UE.Name': 'ue_name',\n",
    "    'Viavi.isEnergySaving': 'is_sleeping'\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ Merged data: {len(df)} active UE data points\")\n",
    "print(f\"✓ Sites: {df['site'].nunique()}\")\n",
    "print(f\"✓ Time points: {df['time'].nunique()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df[['time', 'site', 'band', 'ue_name', 'Cell_PRB', 'UE_Throughput']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in SQLite\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "df.to_sql(TABLE_NAME, engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"✓ Data stored in database table: {TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intent Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Get QoS range from data\n",
    "min_qos = df['UE_Throughput'].min()\n",
    "max_qos = df['UE_Throughput'].max()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OPERATOR INTENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNetwork QoS range: [{min_qos:.1f}, {max_qos:.1f}] Mbps\")\n",
    "\n",
    "# Get intent from user\n",
    "operator_intent = input(\"\\nEnter intent (or press Enter for default): \").strip()\n",
    "\n",
    "# TODO:\n",
    "# Add rejection for no itnent input\n",
    "if not operator_intent:\n",
    "    raise Exception(\"No intent was given.\")\n",
    "\n",
    "else:\n",
    "    # Extract QoS threshold from intent\n",
    "    qos_match = re.search(r'(\\d+)\\s*Mbps', operator_intent, re.IGNORECASE)\n",
    "    if qos_match:\n",
    "        QOS_THRESHOLD = float(qos_match.group(1))\n",
    "    else:\n",
    "        raise Exception(\"No threshold found.\")\n",
    "\n",
    "if QOS_THRESHOLD < min_qos or QOS_THRESHOLD > max_qos:\n",
    "    raise Exception(\"Intent expectation is out of network range capabilities.\")\n",
    "print(f\"\\n✓ Intent: '{operator_intent}'\")\n",
    "print(f\"✓ QoS Threshold: {QOS_THRESHOLD} Mbps\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Virtual Time Zone (VTZ) — Map timestamps to traffic profiles\n",
    "# =============================================================================\n",
    "# Each 15-min interval in the dataset has a real UTC timestamp (e.g. 2023-01-01 01:00 UTC).\n",
    "# VTZ maps any timestamp to the corresponding traffic profile so we know which\n",
    "# RSG simulation configuration (UE count) to use.\n",
    "#\n",
    "# Traffic variation model:\n",
    "#   - Throughput per UE is STATIC (constant across all periods)\n",
    "#   - Number of active UEs varies per period via a multiplier (ue_ratio)\n",
    "#   - ue_count = DEFAULT_UE_COUNT * ue_ratio\n",
    "# =============================================================================\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ---- Scenario defaults ----\n",
    "DEFAULT_UE_COUNT = 200          # Base UE count from default scenario (active UEs in baseline)\n",
    "DEFAULT_THROUGHPUT_MBPS = 8.0   # Static throughput per UE (constant for all periods)\n",
    "\n",
    "\n",
    "# ---- Traffic Profiles (UE ratio model) ---- Early\n",
    "traffic_profiles = [\n",
    "    {\"name\": \"Night\",       \"start_hour\": 0,  \"duration_hours\": 8,  \"ue_ratio\": 0.1, \"description\": \"Low traffic\"},\n",
    "    {\"name\": \"Early\",     \"start_hour\": 8,  \"duration_hours\": 1,  \"ue_ratio\": 1.5, \"description\": \"Medium traffic\"},\n",
    "    {\"name\": \"Morning\",     \"start_hour\": 9,  \"duration_hours\": 4,  \"ue_ratio\": 1, \"description\": \"Normal traffic\"},\n",
    "    {\"name\": \"Afternoon\",   \"start_hour\": 13, \"duration_hours\": 5,  \"ue_ratio\": 0.5, \"description\": \"Normal traffic\"},\n",
    "    {\"name\": \"Evening_1\",     \"start_hour\": 18, \"duration_hours\": 2,  \"ue_ratio\": 2, \"description\": \"Peak traffic\"},\n",
    "    {\"name\": \"Evening_2\",     \"start_hour\": 20, \"duration_hours\": 2,  \"ue_ratio\": 1, \"description\": \"Normal traffic\"},\n",
    "    {\"name\": \"Late Night\",  \"start_hour\": 22, \"duration_hours\": 2,  \"ue_ratio\": 0.1, \"description\": \"Low traffic\"},\n",
    "\n",
    "]\n",
    "\n",
    "# Compute ue_count for each profile\n",
    "for p in traffic_profiles:\n",
    "    p[\"ue_count\"] = int(DEFAULT_UE_COUNT * p[\"ue_ratio\"])\n",
    "\n",
    "# ---- Dict lookup by profile name: traffic_profiles_by_name[\"Night\"] ----\n",
    "traffic_profiles_by_name = {p[\"name\"]: p for p in traffic_profiles}\n",
    "\n",
    "# ---- VTZ mapping function ----\n",
    "def vtz_get_profile(dt):\n",
    "    \"\"\"Map a datetime object to its traffic profile.\"\"\"\n",
    "    hour = dt.hour\n",
    "    for p in traffic_profiles:\n",
    "        if p[\"start_hour\"] <= hour < p[\"start_hour\"] + p[\"duration_hours\"]:\n",
    "            return {**p, \"resolved_hour\": hour, \"resolved_datetime\": dt}\n",
    "    return None\n",
    "\n",
    "# ---- Demo ----\n",
    "print(\"=\"*70)\n",
    "print(\"VIRTUAL TIME ZONE (VTZ) — Traffic Profile Mapping\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nScenario defaults:\")\n",
    "print(f\"  Base UE count:          {DEFAULT_UE_COUNT}\")\n",
    "print(f\"  Static throughput/UE:   {DEFAULT_THROUGHPUT_MBPS} Mbps\")\n",
    "\n",
    "print(f\"\\n{'Profile':<12} {'Hours':<14} {'UE Ratio':<10} {'UE Count':<10} {'Description'}\")\n",
    "print(\"-\"*60)\n",
    "for p in traffic_profiles:\n",
    "    end = p['start_hour'] + p['duration_hours']\n",
    "    print(f\"{p['name']:<12} {p['start_hour']:02d}:00-{end:02d}:00   {p['ue_ratio']:<10.2f} {p['ue_count']:<10} {p['description']}\")\n",
    "\n",
    "# Example mappings\n",
    "print(f\"\\nExample VTZ lookups:\")\n",
    "examples = [\n",
    "    datetime(2023, 1, 1, 1, 0, tzinfo=timezone.utc),\n",
    "    datetime(2023, 1, 1, 8, 30, tzinfo=timezone.utc),\n",
    "    datetime(2023, 1, 1, 14, 0, tzinfo=timezone.utc),\n",
    "    datetime(2023, 1, 1, 19, 0, tzinfo=timezone.utc),\n",
    "]\n",
    "for dt in examples:\n",
    "    profile = vtz_get_profile(dt)\n",
    "    print(f\"  {dt.strftime('%Y-%m-%d %H:%M UTC')}  →  {profile['name']} (ratio={profile['ue_ratio']}, UEs={profile['ue_count']})\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Closed-Loop Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NVIDIA LLM\n",
    "llm = ChatNVIDIA(\n",
    "    model=LLM_MODEL,\n",
    "    api_key=NVIDIA_API_KEY,\n",
    "    temperature=0.1,\n",
    "    max_completion_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Closed-Loop Helper Functions\n",
    "# =============================================================================\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Dict, List, Optional\n",
    "import time as time_module\n",
    "\n",
    "@dataclass\n",
    "class LoopState:\n",
    "    \"\"\"Carries state across closed-loop iterations.\"\"\"\n",
    "    cell_sleep_state: Dict[str, bool] = field(default_factory=dict)   # cell_name -> True if sleeping\n",
    "    prev_kpis: Optional[Dict] = None                                   # KPIs from Sim #2 of previous iteration\n",
    "    iteration_log: List[Dict] = field(default_factory=list)            # accumulated log\n",
    "\n",
    "\n",
    "def datetime_to_baseline_timestamp(Tv, all_timestamps):\n",
    "    \"\"\"Map a Tv datetime to the nearest baseline dataset timestamp (ms).\"\"\"\n",
    "    index = Tv.hour * 4 + Tv.minute // 15\n",
    "    index = min(index, len(all_timestamps) - 1)\n",
    "    return all_timestamps[index]\n",
    "\n",
    "\n",
    "def get_baseline_kpis_for_interval(engine, timestamp_ms, df_ue, df_cell):\n",
    "    \"\"\"Extract per-site KPIs from baseline dataset for a specific 15-min interval.\"\"\"\n",
    "    # Filter baseline data to this timestamp\n",
    "    ue_slice = df_ue[df_ue['time (ms)'] == timestamp_ms]\n",
    "    cell_slice = df_cell[df_cell['time (ms)'] == timestamp_ms]\n",
    "\n",
    "    if len(ue_slice) == 0 and len(cell_slice) == 0:\n",
    "        return None\n",
    "\n",
    "    # Overall metrics\n",
    "    avg_thp = ue_slice['DRB.UEThpDl'].mean() if len(ue_slice) > 0 else 0.0\n",
    "\n",
    "    # Per-site breakdown\n",
    "    per_site = {}\n",
    "    if len(cell_slice) > 0:\n",
    "        for _, row in cell_slice.iterrows():\n",
    "            cell_name = row['Viavi.Cell.Name']\n",
    "            parts = cell_name.split('/')\n",
    "            site = f\"{parts[0]}/{parts[2]}\"\n",
    "            band = parts[1]  # N1 or N12\n",
    "\n",
    "            if site not in per_site:\n",
    "                per_site[site] = {'n1_prb': 0.0, 'n12_prb': 0.0, 'avg_qos': 0.0, 'n1_sleeping': False}\n",
    "\n",
    "            if band == 'N1':\n",
    "                per_site[site]['n1_prb'] = row.get('RRU.PrbTotDl', 0.0)\n",
    "                per_site[site]['n1_sleeping'] = bool(row.get('Viavi.isEnergySaving', 0))\n",
    "            elif band == 'N12':\n",
    "                per_site[site]['n12_prb'] = row.get('RRU.PrbTotDl', 0.0)\n",
    "\n",
    "    # Add avg QoS per site from UE data\n",
    "    if len(ue_slice) > 0:\n",
    "        for _, row in ue_slice.iterrows():\n",
    "            cell_name = row['Viavi.Cell.Name']\n",
    "            parts = cell_name.split('/')\n",
    "            site = f\"{parts[0]}/{parts[2]}\"\n",
    "            if site in per_site:\n",
    "                # accumulate - will average later\n",
    "                if 'qos_values' not in per_site[site]:\n",
    "                    per_site[site]['qos_values'] = []\n",
    "                per_site[site]['qos_values'].append(row['DRB.UEThpDl'])\n",
    "\n",
    "    # Average QoS\n",
    "    for site in per_site:\n",
    "        if 'qos_values' in per_site[site]:\n",
    "            per_site[site]['avg_qos'] = sum(per_site[site]['qos_values']) / len(per_site[site]['qos_values'])\n",
    "            del per_site[site]['qos_values']\n",
    "\n",
    "    sleeping_count = sum(1 for s in per_site.values() if s.get('n1_sleeping', False))\n",
    "    total_count = len(per_site) * 2\n",
    "\n",
    "    return {\n",
    "        'avg_throughput_mbps': avg_thp,\n",
    "        'sleeping_cells': sleeping_count,\n",
    "        'total_cells': total_count,\n",
    "        'per_site': per_site,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_kpis(sim_ue, sim_cell):\n",
    "    \"\"\"Transform raw RSG query results into structured KPI dict.\"\"\"\n",
    "    avg_thp = sim_ue['DRB.UEThpDl'].mean() if len(sim_ue) > 0 else 0.0\n",
    "\n",
    "    per_site = {}\n",
    "    if len(sim_cell) > 0:\n",
    "        for _, row in sim_cell.iterrows():\n",
    "            cell_name = row['Viavi.Cell.Name']\n",
    "            parts = cell_name.split('/')\n",
    "            site = f\"{parts[0]}/{parts[2]}\"\n",
    "            band = parts[1]\n",
    "\n",
    "            if site not in per_site:\n",
    "                per_site[site] = {'n1_prb': 0.0, 'n12_prb': 0.0, 'avg_qos': 0.0, 'n1_sleeping': False}\n",
    "\n",
    "            if band == 'N1':\n",
    "                per_site[site]['n1_prb'] = row.get('RRU.PrbTotDl', 0.0)\n",
    "                per_site[site]['n1_sleeping'] = bool(row.get('Viavi.isEnergySaving', 0))\n",
    "            elif band == 'N12':\n",
    "                per_site[site]['n12_prb'] = row.get('RRU.PrbTotDl', 0.0)\n",
    "\n",
    "    # UE throughput per site\n",
    "    if len(sim_ue) > 0:\n",
    "        for _, row in sim_ue.iterrows():\n",
    "            cell_name = row['Viavi.Cell.Name']\n",
    "            parts = cell_name.split('/')\n",
    "            site = f\"{parts[0]}/{parts[2]}\"\n",
    "            if site in per_site:\n",
    "                if 'qos_values' not in per_site[site]:\n",
    "                    per_site[site]['qos_values'] = []\n",
    "                per_site[site]['qos_values'].append(row['DRB.UEThpDl'])\n",
    "\n",
    "    for site in per_site:\n",
    "        if 'qos_values' in per_site[site]:\n",
    "            per_site[site]['avg_qos'] = sum(per_site[site]['qos_values']) / len(per_site[site]['qos_values'])\n",
    "            del per_site[site]['qos_values']\n",
    "\n",
    "    sleeping_count = sum(1 for s in per_site.values() if s.get('n1_sleeping', False))\n",
    "\n",
    "    return {\n",
    "        'avg_throughput_mbps': avg_thp,\n",
    "        'sleeping_cells': sleeping_count,\n",
    "        'total_cells': len(per_site) * 2,\n",
    "        'per_site': per_site,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_kpis_for_prompt(kpis):\n",
    "    \"\"\"Format KPI dict into a readable table string for LLM prompts.\"\"\"\n",
    "    if kpis is None:\n",
    "        return \"No previous KPI data available.\"\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"Overall: avg_throughput={kpis['avg_throughput_mbps']:.2f} Mbps, \"\n",
    "                 f\"sleeping_cells={kpis['sleeping_cells']}/{kpis['total_cells']}\")\n",
    "\n",
    "    if kpis.get('per_site'):\n",
    "        lines.append(f\"{'Site':<8} | {'N1 PRB':>7} | {'N12 PRB':>8} | {'Avg QoS':>9} | {'N1 State':>10}\")\n",
    "        lines.append(\"-\" * 55)\n",
    "        for site in sorted(kpis['per_site'].keys()):\n",
    "            s = kpis['per_site'][site]\n",
    "            state = \"Sleeping\" if s.get('n1_sleeping', False) else \"Awake\"\n",
    "            lines.append(f\"{site:<8} | {s['n1_prb']:>6.1f}% | {s['n12_prb']:>7.1f}% | \"\n",
    "                         f\"{s['avg_qos']:>7.2f}   | {state:>10}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def llm_generate_recommendations(llm, Tv, profile, loop_state, operator_intent,\n",
    "                                  qos_threshold, all_sites, engine, df_ue, df_cell,\n",
    "                                  all_timestamps):\n",
    "    \"\"\"LLM #1: Generate Sleep/Wake recommendations via SQL generation for current Tv interval.\"\"\"\n",
    "    import pandas as pd\n",
    "    from sqlalchemy import text\n",
    "\n",
    "    # Get baseline KPIs for this interval\n",
    "    ts_ms = datetime_to_baseline_timestamp(Tv, all_timestamps)\n",
    "    baseline_kpis = get_baseline_kpis_for_interval(engine, ts_ms, df_ue, df_cell)\n",
    "    baseline_text = format_kpis_for_prompt(baseline_kpis) if baseline_kpis else \"No baseline data for this interval.\"\n",
    "\n",
    "    # Format previous iteration results\n",
    "    prev_text = format_kpis_for_prompt(loop_state.prev_kpis) if loop_state.prev_kpis else \"No previous iteration data (first iteration).\"\n",
    "\n",
    "    # ── Step 1: Write current cell_sleep_state into SQLite as cell_states table ──\n",
    "    cell_states_rows = []\n",
    "    for cell_name, is_sleeping in loop_state.cell_sleep_state.items():\n",
    "        parts = cell_name.split(\"/\")  # e.g. \"S1/N1/C1\" -> [\"S1\", \"N1\", \"C1\"]\n",
    "        site = f\"{parts[0]}/{parts[2]}\" if len(parts) == 3 else cell_name\n",
    "        band = parts[1] if len(parts) == 3 else \"\"\n",
    "        cell_states_rows.append({\n",
    "            'site': site,\n",
    "            'band': band,\n",
    "            'cell_full': cell_name,\n",
    "            'current_is_sleeping': int(is_sleeping)\n",
    "        })\n",
    "    if cell_states_rows:\n",
    "        df_states = pd.DataFrame(cell_states_rows)\n",
    "    else:\n",
    "        # Initial state: all awake\n",
    "        df_states = pd.DataFrame([\n",
    "            {'site': s, 'band': 'N1', 'cell_full': s.split('/')[0] + '/N1/' + s.split('/')[1], 'current_is_sleeping': 0}\n",
    "            for s in all_sites\n",
    "        ])\n",
    "    df_states.to_sql('cell_states', engine, if_exists='replace', index=False)\n",
    "\n",
    "    # ── Step 2: Build SQL generation prompt ──\n",
    "    sleep_states_text = \"\"\n",
    "    if loop_state.cell_sleep_state:\n",
    "        sleeping = [c for c, v in loop_state.cell_sleep_state.items() if v]\n",
    "        awake = [c for c, v in loop_state.cell_sleep_state.items() if not v]\n",
    "        sleep_states_text = f\"Currently sleeping: {sleeping if sleeping else 'None'}\\nCurrently awake: {awake if awake else 'All cells awake'}\"\n",
    "    else:\n",
    "        sleep_states_text = \"All cells awake (initial state).\"\n",
    "\n",
    "    prompt_text = f\"\"\"**Operator Intent:** \"{operator_intent}\" (QoS threshold: {qos_threshold} Mbps)\n",
    "\n",
    "**Current Time:** {Tv.strftime('%Y-%m-%d %H:%M UTC')}\n",
    "**Traffic Profile:** {profile['name']} (UE ratio: {profile['ue_ratio']}, description: {profile['description']})\n",
    "\n",
    "**Current Cell States:**\n",
    "{sleep_states_text}\n",
    "\n",
    "**Previous Iteration RSG Simulation Results:**\n",
    "{prev_text}\n",
    "\n",
    "**Baseline Dataset KPIs for this interval:**\n",
    "{baseline_text}\n",
    "\n",
    "**Task:** Generate a SQL query to analyze network conditions and make energy saving decisions for the current timestamp.\n",
    "\n",
    "**Database Schema:**\n",
    "- Table: kpi_data\n",
    "  Columns: time (milliseconds), site, band ('N1' or 'N12'), cell_full, ue_name, Cell_PRB (%), UE_Throughput (Mbps), is_sleeping (0/1)\n",
    "- Table: cell_states\n",
    "  Columns: site, band, cell_full, current_is_sleeping (0=awake, 1=sleeping)\n",
    "\n",
    "**IMPORTANT:** Use `band` column (not `cell`) to distinguish N1 vs N12.\n",
    "**IMPORTANT:** Use `WHERE kd.time = {ts_ms}` to scope to the current 15-minute interval only.\n",
    "**IMPORTANT:** JOIN with cell_states to get the current sleep state (do NOT use is_sleeping from kpi_data).\n",
    "\n",
    "**Decision Rules (QoS threshold = {qos_threshold} Mbps):**\n",
    "  SLEEP_CONDITION_1: (n1_prb = 0) AND (n12_prb = 0)\n",
    "  SLEEP_CONDITION_2: (n12_prb < 35) AND (n1_prb < 12) AND (avg_qos >= {qos_threshold})\n",
    "\n",
    "  For each site:\n",
    "    IF current_is_sleeping = 1 AND n12_prb > 60 -> 'Wake'\n",
    "    ELIF current_is_sleeping = 0 AND (SLEEP_CONDITION_1 OR SLEEP_CONDITION_2) -> 'Sleep'\n",
    "    ELSE -> 'No Action'\n",
    "\n",
    "**Required SQL Structure (follow this CTE pattern):**\n",
    "```sql\n",
    "WITH site_metrics AS (\n",
    "  SELECT\n",
    "    kd.site,\n",
    "    COALESCE(MAX(CASE WHEN kd.band = 'N1' THEN kd.Cell_PRB END), 0) as n1_prb,\n",
    "    COALESCE(MAX(CASE WHEN kd.band = 'N12' THEN kd.Cell_PRB END), 0) as n12_prb,\n",
    "    COALESCE(AVG(kd.UE_Throughput), 0) as avg_qos,\n",
    "    COALESCE(MAX(CASE WHEN cs.band = 'N1' THEN cs.current_is_sleeping END), 0) as current_is_sleeping\n",
    "  FROM kpi_data kd\n",
    "  LEFT JOIN cell_states cs ON kd.site = cs.site AND kd.band = cs.band\n",
    "  WHERE kd.time = {ts_ms}\n",
    "  GROUP BY kd.site\n",
    ")\n",
    "SELECT\n",
    "  site,\n",
    "  CASE\n",
    "    WHEN current_is_sleeping = 1 AND n12_prb > 60 THEN 'Wake'\n",
    "    WHEN current_is_sleeping = 0 AND ((n1_prb = 0 AND n12_prb = 0) OR (n12_prb < 35 AND n1_prb < 12 AND avg_qos >= {qos_threshold})) THEN 'Sleep'\n",
    "    ELSE 'No Action'\n",
    "  END as action,\n",
    "  CASE\n",
    "    WHEN current_is_sleeping = 1 AND n12_prb > 60 THEN 'N12 PRB=' || ROUND(n12_prb,1) || '% exceeds 60%, waking N1'\n",
    "    WHEN current_is_sleeping = 0 AND n1_prb = 0 AND n12_prb = 0 THEN 'No traffic (N1 PRB=0%, N12 PRB=0%)'\n",
    "    WHEN current_is_sleeping = 0 AND (n12_prb < 35 AND n1_prb < 12 AND avg_qos >= {qos_threshold}) THEN 'Low util (N1=' || ROUND(n1_prb,1) || '%, N12=' || ROUND(n12_prb,1) || '%, QoS=' || ROUND(avg_qos,2) || ' >= {qos_threshold})'\n",
    "    ELSE 'No action needed'\n",
    "  END as reason\n",
    "FROM site_metrics\n",
    "ORDER BY site;\n",
    "```\n",
    "\n",
    "**Output columns:** site, action, reason\n",
    "\n",
    "Generate SQL following this exact structure. Return ONLY the SQL code.\"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a SQL expert for SQLite databases. Generate clean, executable SQL queries. Return only the SQL code.\"),\n",
    "        (\"user\", prompt_text)\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "    response = chain.invoke({})\n",
    "\n",
    "    # ── Step 3: Extract SQL from response ──\n",
    "    if \"```sql\" in response:\n",
    "        generated_sql = response.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
    "    elif \"```\" in response:\n",
    "        generated_sql = response.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "    else:\n",
    "        generated_sql = response.strip()\n",
    "\n",
    "\n",
    "    # Safety net: fix common LLM mistake of using \"cell\" instead of \"band\"\n",
    "    import re\n",
    "    generated_sql = re.sub(r'\\bWHEN\\s+cell\\s*=', 'WHEN band =', generated_sql, flags=re.IGNORECASE)\n",
    "    generated_sql = re.sub(r'\\bkd\\.cell\\b', 'kd.band', generated_sql, flags=re.IGNORECASE)\n",
    "    generated_sql = re.sub(r'\\bcs\\.cell\\b', 'cs.band', generated_sql, flags=re.IGNORECASE)\n",
    "    print(f\"   Generated SQL: {generated_sql[:200]}...\")\n",
    "\n",
    "    # ── Step 4: Execute SQL against SQLite ──\n",
    "    with engine.connect() as conn:\n",
    "        result_df = pd.read_sql(text(generated_sql), conn)\n",
    "\n",
    "    # Post-process: add target_cell column (S1/C1 → S1/N1/C1)\n",
    "    if len(result_df) > 0:\n",
    "        result_df['target_cell'] = result_df['site'].apply(\n",
    "            lambda s: s.split('/')[0] + '/N1/' + s.split('/')[1]\n",
    "        )\n",
    "        # Filter to only Sleep/Wake rows (exclude No Action)\n",
    "        result_df = result_df[result_df['action'].isin(['Sleep', 'Wake'])].reset_index(drop=True)\n",
    "        result_df = result_df[['site', 'target_cell', 'action', 'reason']].drop_duplicates(\n",
    "            subset=['target_cell', 'action']\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    return result_df if len(result_df) > 0 else pd.DataFrame(columns=['site', 'target_cell', 'action', 'reason'])\n",
    "\n",
    "\n",
    "def llm_validate_recommendations(llm, recommendations_df, sim1_kpis, Tv, profile,\n",
    "                                  loop_state, operator_intent, qos_threshold):\n",
    "    \"\"\"LLM #2: Validate Sleep recommendations using Sim #1 KPIs (QoS check only).\n",
    "    Returns approved-only DataFrame.\"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if len(recommendations_df) == 0:\n",
    "        return pd.DataFrame(columns=['site', 'target_cell', 'action', 'reason'])\n",
    "\n",
    "    # Format recommendations + sim1 KPIs\n",
    "    recs_text = \"\"\n",
    "    for idx, row in recommendations_df.iterrows():\n",
    "        site = row['site']\n",
    "        site_kpis = sim1_kpis.get('per_site', {}).get(site, {})\n",
    "        recs_text += (f\"{idx+1} | {row['action']} | {row['target_cell']} | \"\n",
    "                      f\"QoS:{site_kpis.get('avg_qos', 0):.2f}Mbps | {row['reason']}\\n\")\n",
    "\n",
    "    sim_summary = format_kpis_for_prompt(sim1_kpis)\n",
    "\n",
    "    prompt_text = f\"\"\"**Operator Intent:** \"{operator_intent}\" (QoS threshold: {qos_threshold} Mbps)\n",
    "**Current Time:** {Tv.strftime('%Y-%m-%d %H:%M UTC')}\n",
    "**Traffic Profile:** {profile['name']}\n",
    "\n",
    "**RSG Simulation #1 Results (testing Sleep recommendations):**\n",
    "{sim_summary}\n",
    "\n",
    "**Recommendations to Validate (# | ACTION | CELL | QoS | REASON):**\n",
    "{recs_text}\n",
    "\n",
    "**Task:** For each Sleep recommendation, decide YES (approve) or NO (reject).\n",
    "\n",
    "NOTE: N1 cells are already sleeping in Sim #1 results, so N1 PRB will be 0 by\n",
    "definition. Focus on N12 PRB and QoS to judge impact.\n",
    "\n",
    "**Validation Rules (evaluate in order, stop at first match):**\n",
    "APPROVE_RULE_1: N12_PRB == 0 → YES (no traffic at site, Sleep has zero impact)\n",
    "APPROVE_RULE_2: AVG_QOS >= {qos_threshold} Mbps → YES (QoS maintained despite Sleep)\n",
    "REJECT_RULE:    AVG_QOS < {qos_threshold} Mbps AND N12_PRB > 0 → NO (Sleep degraded QoS)\n",
    "\n",
    "**Examples:**\n",
    "1 | Sleep | S1/N1/C1 | N12_PRB=0.0%, QoS=N/A   → 1 | YES | No traffic at site (APPROVE_RULE_1)\n",
    "2 | Sleep | S2/N1/C1 | N12_PRB=25%, QoS=5.20    → 2 | YES | QoS 5.20 >= {qos_threshold} (APPROVE_RULE_2)\n",
    "3 | Sleep | S3/N1/C1 | N12_PRB=45%, QoS=1.50    → 3 | NO  | QoS 1.50 < {qos_threshold}, site has traffic (REJECT_RULE)\n",
    "4 | Sleep | S4/N1/C1 | N12_PRB=12%, QoS={qos_threshold - 0.1:.1f}    → 4 | NO  | QoS {qos_threshold - 0.1:.1f} < {qos_threshold}, site has traffic\n",
    "(REJECT_RULE)\n",
    "\n",
    "Now validate the actual recommendations:\n",
    "\n",
    "Reply ONLY in format: NUM | YES/NO | RULE_NAME | reason\"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a 5G network validation expert. Approve or reject Sleep recommendations based on QoS impact from RSG simulation results. Reply in format: NUM | YES/NO | reason\"),\n",
    "        (\"user\", prompt_text)\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "    response = chain.invoke({})\n",
    "\n",
    "    # Parse response\n",
    "    approved_indices = set()\n",
    "    for line in response.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if '|' in line:\n",
    "            parts = [p.strip() for p in line.split('|')]\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    num = int(parts[0].replace('.', '').strip())\n",
    "                    decision = parts[1].strip().upper()\n",
    "                    if 'YES' in decision:\n",
    "                        approved_indices.add(num - 1)  # convert to 0-based\n",
    "                except (ValueError, IndexError):\n",
    "                    pass\n",
    "\n",
    "    # Filter to approved only (guard against out-of-bounds indices from LLM)\n",
    "    valid_indices = sorted(i for i in approved_indices if 0 <= i < len(recommendations_df))\n",
    "    if valid_indices:\n",
    "        approved_df = recommendations_df.iloc[valid_indices].copy()\n",
    "    else:\n",
    "        approved_df = pd.DataFrame(columns=['site', 'target_cell', 'action', 'reason'])\n",
    "\n",
    "    return approved_df\n",
    "  \n",
    "\n",
    "_original_ue_distribution = None\n",
    "\n",
    "# =============================================================================\n",
    "# IMPROVED run_sim — Persistent simulation with warm-up & aggregation\n",
    "# =============================================================================\n",
    "\n",
    "_persistent_sim = None          # Keep simulation alive across iterations\n",
    "_original_ue_distribution = None\n",
    "SIM_DURATION = 10               # RSG default: 10s simulation, last second is steady-state\n",
    "\n",
    "\n",
    "def run_sim(scenario, profile, actions_to_apply, loop_state):\n",
    "  \"\"\"Run RSG simulation with default 10s duration.\n",
    "\n",
    "  RSG stabilizes within 10 seconds. Query start=9, stop=10 returns\n",
    "  the last second of steady-state data (42 rows for CellReports,\n",
    "  one per cell).\n",
    "  \"\"\"\n",
    "  global _persistent_sim, _original_ue_distribution\n",
    "\n",
    "  # 1. Scale UE count\n",
    "  if _original_ue_distribution is None:\n",
    "      _original_ue_distribution = []\n",
    "      for ue_group in scenario.config[\"UE_Configuration\"][\"UE_Groups\"]:\n",
    "          group_dists = []\n",
    "          for dist in ue_group.get(\"distribution\", []):\n",
    "              group_dists.append(dist[\"ues\"])\n",
    "          _original_ue_distribution.append(group_dists)\n",
    "\n",
    "  for g_idx, ue_group in enumerate(scenario.config[\"UE_Configuration\"][\"UE_Groups\"]):\n",
    "      for d_idx, dist in enumerate(ue_group.get(\"distribution\", [])):\n",
    "          original_ues = _original_ue_distribution[g_idx][d_idx]\n",
    "          dist[\"ues\"] = max(1, int(original_ues * profile['ue_ratio']))\n",
    "      if \"serviceConfig\" in ue_group:\n",
    "          for service in ue_group[\"serviceConfig\"]:\n",
    "              service[\"targetTput_Mbps\"] = DEFAULT_THROUGHPUT_MBPS\n",
    "\n",
    "  # 2. Configure batch mode\n",
    "  scenario.config['System']['batch_mode'] = True\n",
    "  scenario.config['System']['duration'] = SIM_DURATION\n",
    "\n",
    "  # 3. Start simulation (fresh start needed because UE config changed)\n",
    "  sim = scenario.simulation(force_start=True, adk_pace=True)\n",
    "  sim.start()\n",
    "\n",
    "  # 4. Re-apply accumulated sleep states\n",
    "  for cell_name, is_sleeping in loop_state.cell_sleep_state.items():\n",
    "      if is_sleeping:\n",
    "          sim.command('turn_off', cell=cell_name, reason='Accumulated sleep state')\n",
    "      else:\n",
    "          sim.command('turn_on', cell=cell_name, reason='Accumulated awake state')\n",
    "\n",
    "  # 5. Apply new actions\n",
    "  if actions_to_apply is not None and len(actions_to_apply) > 0:\n",
    "      for _, row in actions_to_apply.iterrows():\n",
    "          target_cell = row['target_cell']\n",
    "          action = row['action']\n",
    "          if action == 'Sleep':\n",
    "              sim.command('turn_off', cell=target_cell,\n",
    "                         reason=row.get('reason', 'Energy optimization'))\n",
    "          elif action == 'Wake':\n",
    "              sim.command('turn_on', cell=target_cell,\n",
    "                         reason=row.get('reason', 'Capacity needed'))\n",
    "\n",
    "  # 6. Run for default duration\n",
    "  sim.run_for(f\"{SIM_DURATION}s\")\n",
    "\n",
    "  # 7. Query last second of steady-state data\n",
    "  sim_ue = sim.query(\"UEReports\", start=9, stop=10)\n",
    "  sim_cell = sim.query(\"CellReports\", start=9, stop=10)\n",
    "\n",
    "  # 8. Stop simulation\n",
    "  sim.finish()\n",
    "\n",
    "  # 9. Compute KPIs from last-second snapshot\n",
    "  # Deduplicate: RSG returns multiple samples per cell\n",
    "  sim_cell = sim_cell.drop_duplicates(subset=['Viavi.Cell.Name'], keep='last').reset_index(drop=True)\n",
    "  return compute_kpis(sim_ue, sim_cell), sim_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_efficiency(summary_df):\n",
    "    \"\"\"Compute energy efficiency KPI based on % of sleeping cells over the simulation window.\"\"\"\n",
    "    if summary_df.empty:\n",
    "        print(\"\\n  No iteration data — cannot compute energy efficiency.\")\n",
    "        return\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    ratios = summary_df['sleeping_cells'] / summary_df['total_cells']\n",
    "    avg_ratio = ratios.mean()\n",
    "    num_intervals = len(summary_df)\n",
    "    window_hours = num_intervals * 15 / 60\n",
    "    total_cells = int(summary_df['total_cells'].iloc[0])\n",
    "\n",
    "    print(f\"\\nENERGY EFFICIENCY KPI (Sleeping Cell Ratio)\")\n",
    "    print(\"─\" * 60)\n",
    "    print(f\"  Window: {num_intervals} intervals ({window_hours:.1f} hours)\")\n",
    "    print(f\"  Total cells: {total_cells} (21 N1 + 21 N12)\")\n",
    "    print(f\"  Theoretical max: 50.0% (only N1 cells can sleep)\")\n",
    "    print(f\"  Average sleeping cell ratio: {avg_ratio * 100:.1f}%\")\n",
    "    print(f\"  → Estimated energy saving potential: ~{avg_ratio * 100:.1f}%\")\n",
    "\n",
    "    # Per-profile breakdown\n",
    "    profile_ratios = defaultdict(list)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        dt = datetime.strptime(row['time_utc'], '%Y-%m-%d %H:%M')\n",
    "        profile = vtz_get_profile(dt.replace(tzinfo=timezone.utc))\n",
    "        if profile:\n",
    "            ratio = row['sleeping_cells'] / row['total_cells']\n",
    "            profile_ratios[profile['name']].append(ratio)\n",
    "\n",
    "    if profile_ratios:\n",
    "        print(f\"\\n  Per-profile breakdown:\")\n",
    "        for p in traffic_profiles:\n",
    "            name = p['name']\n",
    "            if name in profile_ratios:\n",
    "                avg = sum(profile_ratios[name]) / len(profile_ratios[name])\n",
    "                count = len(profile_ratios[name])\n",
    "                print(f\"    {name:<12} ({count:>2} intervals): {avg * 100:5.1f}% cells sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Main Closed-Loop Function\n",
    "# =============================================================================\n",
    "\n",
    "def run_closed_loop(llm, scenario, engine, df_ue, df_cell, all_timestamps,\n",
    "                    all_sites, operator_intent, qos_threshold,\n",
    "                    start_datetime, num_iterations):\n",
    "    \"\"\"\n",
    "    Run the closed-loop per-interval iteration engine.\n",
    "\n",
    "    7-step loop per iteration:\n",
    "      1. LLM #1: Generate Sleep/Wake recommendations\n",
    "      2. Blueprint picks (implicit — LLM is profile-aware)\n",
    "      3. RSG Sim #1: Test Sleep recommendations with current profile\n",
    "         (Wake recs bypass — wake is non-destructive per Flow.md)\n",
    "      4. LLM #2: Validate Sleep recs using Sim #1 KPIs → approved list\n",
    "         Wake recs auto-approved and concatenated\n",
    "      5. Advance Tv by 15 min\n",
    "      6. RSG Sim #2: Apply approved actions with next profile\n",
    "      7. Feed Sim #2 KPIs back to next iteration\n",
    "\n",
    "    Returns:\n",
    "        (loop_state, summary_df) — LoopState and DataFrame of iteration summaries\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    loop_state = LoopState()\n",
    "    Tv = start_datetime\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CLOSED-LOOP PER-INTERVAL ENGINE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Start time: {Tv.strftime('%Y-%m-%d %H:%M UTC')}\")\n",
    "    print(f\"Iterations: {num_iterations}\")\n",
    "    print(f\"Operator intent: {operator_intent}\")\n",
    "    print(f\"QoS threshold: {qos_threshold} Mbps\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    engine_start = time_module.time()\n",
    "\n",
    "    # Persistent log file\n",
    "    log_dir = str(PROJECT_ROOT / 'output')\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_path = f\"{log_dir}/closed_loop_log.txt\"\n",
    "    log_file = open(log_path, 'w')\n",
    "    log_file.write(f\"CLOSED-LOOP SIMULATION LOG\\n\")\n",
    "    log_file.write(f\"Start: {start_datetime.strftime('%Y-%m-%d %H:%M UTC')}\\n\")\n",
    "    log_file.write(f\"Iterations: {num_iterations}\\n\")\n",
    "    log_file.write(f\"Intent: {operator_intent}\\n\")\n",
    "    log_file.write(f\"QoS threshold: {qos_threshold} Mbps\\n\")\n",
    "    log_file.write(\"=\" * 80 + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        iter_start = time_module.time()\n",
    "        profile = vtz_get_profile(Tv)\n",
    "        if profile is None:\n",
    "            print(f\"\\n⚠ Iteration {iteration+1}: No profile for {Tv}, skipping\")\n",
    "            Tv = Tv + timedelta(minutes=15)\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'─' * 80}\")\n",
    "        print(f\"ITERATION {iteration+1}/{num_iterations} | {Tv.strftime('%H:%M UTC')} | Profile: {profile['name']} (ratio={profile['ue_ratio']})\")\n",
    "        print(f\"{'─' * 80}\")\n",
    "\n",
    "        sleeping_count = sum(1 for v in loop_state.cell_sleep_state.values() if v)\n",
    "        print(f\"  Current state: {sleeping_count} cells sleeping\")\n",
    "\n",
    "        # Seed prev_kpis from baseline on first iteration\n",
    "        if loop_state.prev_kpis is None:\n",
    "            ts_ms = datetime_to_baseline_timestamp(Tv, all_timestamps)\n",
    "            loop_state.prev_kpis = get_baseline_kpis_for_interval(engine, ts_ms, df_ue, df_cell)\n",
    "            print(f\"  Stored prev_kpis from baseline (ts={ts_ms})\")\n",
    "\n",
    "        # Fetch baseline KPIs for this interval (for logging)\n",
    "        ts_ms = datetime_to_baseline_timestamp(Tv, all_timestamps)\n",
    "        baseline_kpis = get_baseline_kpis_for_interval(engine, ts_ms, df_ue, df_cell)\n",
    "        if iteration == 0:\n",
    "            _bl_sites = len(baseline_kpis.get('per_site', {})) if baseline_kpis else 0\n",
    "            _bl_cells = baseline_kpis.get('total_cells', 0) if baseline_kpis else 0\n",
    "            print(f\"  [BASELINE DEBUG] sites={_bl_sites}, total_cells={_bl_cells}, \"\n",
    "                  f\"df_cell rows at ts={len(df_cell[df_cell['time (ms)']==ts_ms])}\")\n",
    "\n",
    "        # ── Step 1: LLM #1 — Generate recommendations ──\n",
    "        print(f\"  Step 1: LLM generating recommendations...\")\n",
    "        t0 = time_module.time()\n",
    "        recommendations = llm_generate_recommendations(\n",
    "            llm, Tv, profile, loop_state, operator_intent,\n",
    "            qos_threshold, all_sites, engine, df_ue, df_cell, all_timestamps\n",
    "        )\n",
    "        t_llm1 = time_module.time() - t0\n",
    "\n",
    "        # Split: Wake bypasses Sim #1 + LLM #2 (wake is non-destructive)\n",
    "        sleep_recs = recommendations[recommendations['action'] == 'Sleep'].drop_duplicates(subset=['target_cell']).reset_index(drop=True)\n",
    "        wake_recs = recommendations[recommendations['action'] == 'Wake'].drop_duplicates(subset=['target_cell']).reset_index(drop=True)\n",
    "        n_sleep, n_wake = len(sleep_recs), len(wake_recs)\n",
    "\n",
    "        parts = []\n",
    "        if n_sleep > 0:\n",
    "            parts.append(f\"{n_sleep} Sleep\")\n",
    "        if n_wake > 0:\n",
    "            parts.append(f\"{n_wake} Wake (auto-approved)\")\n",
    "        count_str = \", \".join(parts) if parts else \"0\"\n",
    "        print(f\"    → {len(recommendations)} recommendations generated: {count_str} ({t_llm1:.1f}s)\")\n",
    "        if len(recommendations) > 0:\n",
    "            for _, r in recommendations.iterrows():\n",
    "                tag = \" [auto-approved]\" if r['action'] == 'Wake' else \"\"\n",
    "                print(f\"      {r['action']:5s} {r['target_cell']} — {r.get('reason', '')[:60]}{tag}\")\n",
    "\n",
    "        # ── Step 2: Blueprint picks (implicit in LLM prompt) ──\n",
    "\n",
    "        # ── Step 3: RSG Sim #1 — Test Sleep recommendations only ──\n",
    "        t_sim1 = 0.0\n",
    "        if n_sleep > 0:\n",
    "            print(f\"  Step 3: RSG Sim #1 (testing {n_sleep} Sleep recommendations)...\")\n",
    "            t0 = time_module.time()\n",
    "            sim1_kpis, sim1_cell = run_sim(scenario, profile, sleep_recs, loop_state)\n",
    "            t_sim1 = time_module.time() - t0\n",
    "            print(f\"    → avg_thp={sim1_kpis['avg_throughput_mbps']:.2f} Mbps, \"\n",
    "                  f\"sleeping={sim1_kpis['sleeping_cells']}/{sim1_kpis['total_cells']} ({t_sim1:.1f}s)\")\n",
    "            if len(sim1_cell) > 0:\n",
    "                for _, sr in sleep_recs.iterrows():\n",
    "                    cell_row = sim1_cell[sim1_cell['Viavi.Cell.Name'] == sr['target_cell']]\n",
    "\n",
    "        else:\n",
    "            sim1_kpis = loop_state.prev_kpis or {}\n",
    "            print(f\"  Step 3: Skipped (no Sleep recommendations)\")\n",
    "\n",
    "        t_llm2 = 0.0\n",
    "        # ── Step 4: LLM #2 — Validate Sleep recommendations only ──\n",
    "        if n_sleep > 0:\n",
    "            print(f\"  Step 4: LLM validating {n_sleep} Sleep recommendations...\")\n",
    "            t0 = time_module.time()\n",
    "            approved_sleep = llm_validate_recommendations(\n",
    "                llm, sleep_recs, sim1_kpis, Tv, profile,\n",
    "                loop_state, operator_intent, qos_threshold\n",
    "            )\n",
    "            t_llm2 = time_module.time() - t0\n",
    "        else:\n",
    "            approved_sleep = pd.DataFrame(columns=['site', 'target_cell', 'action', 'reason'])\n",
    "\n",
    "        # Wake always approved — concat with validated Sleep\n",
    "        approved = pd.concat([approved_sleep, wake_recs], ignore_index=True)\n",
    "\n",
    "        # Print Step 4 summary\n",
    "        if n_sleep > 0 or n_wake > 0:\n",
    "            parts = []\n",
    "            if n_sleep > 0:\n",
    "                parts.append(f\"{len(approved_sleep)}/{n_sleep} Sleep approved\")\n",
    "            if n_wake > 0:\n",
    "                parts.append(f\"{n_wake} Wake (auto-approved)\")\n",
    "            summary = \" + \".join(parts) + f\" = {len(approved)} total\"\n",
    "            print(f\"    → {summary} ({t_llm2:.1f}s)\")\n",
    "            if len(approved) > 0:\n",
    "                for _, a in approved.iterrows():\n",
    "                    tag = \" [auto]\" if a['action'] == 'Wake' else \"\"\n",
    "                    print(f\"      ✓ {a['action']:5s} {a['target_cell']}{tag}\")\n",
    "        else:\n",
    "            print(f\"  Step 4: Skipped (no recommendations)\")\n",
    "\n",
    "        # ── Step 5: Advance Tv ──\n",
    "        Tv = Tv + timedelta(minutes=15)\n",
    "        next_profile = vtz_get_profile(Tv)\n",
    "        if next_profile is None:\n",
    "            # Wrap around to start of day\n",
    "            Tv = Tv.replace(hour=0, minute=0)\n",
    "            next_profile = vtz_get_profile(Tv)\n",
    "        print(f\"  Step 5: Tv → {Tv.strftime('%H:%M UTC')} (profile: {next_profile['name']})\")\n",
    "\n",
    "        # ── Step 6: RSG Sim #2 — Apply approved actions ──\n",
    "        # Update cell_sleep_state ONLY from approved actions\n",
    "        if len(approved) > 0:\n",
    "            for _, row in approved.iterrows():\n",
    "                cell_name = row['target_cell']\n",
    "                if row['action'] == 'Sleep':\n",
    "                    loop_state.cell_sleep_state[cell_name] = True\n",
    "                elif row['action'] == 'Wake':\n",
    "                    loop_state.cell_sleep_state[cell_name] = False\n",
    "\n",
    "        print(f\"  Step 6: RSG Sim #2 (approved actions + next profile)...\")\n",
    "        t0 = time_module.time()\n",
    "        sim2_kpis, sim2_cell = run_sim(scenario, next_profile, None, loop_state)\n",
    "        t_sim2 = time_module.time() - t0\n",
    "        # NOTE: actions already in cell_sleep_state, no new actions passed\n",
    "        print(f\"    → avg_thp={sim2_kpis['avg_throughput_mbps']:.2f} Mbps, \"\n",
    "              f\"sleeping={sim2_kpis['sleeping_cells']}/{sim2_kpis['total_cells']} ({t_sim2:.1f}s)\")\n",
    "        if len(approved) > 0 and len(sim2_cell) > 0:\n",
    "            for _, ar in approved.iterrows():\n",
    "                cell_row = sim2_cell[sim2_cell['Viavi.Cell.Name'] == ar['target_cell']]\n",
    "\n",
    "        # ── Step 7: Feed back ──\n",
    "        loop_state.prev_kpis = sim2_kpis\n",
    "\n",
    "        sleeping_after = sum(1 for v in loop_state.cell_sleep_state.values() if v)\n",
    "        iter_elapsed = time_module.time() - iter_start\n",
    "   \n",
    "        loop_state.iteration_log.append({\n",
    "            'iteration': iteration + 1,\n",
    "            'time_utc': (Tv - timedelta(minutes=15)).strftime('%Y-%m-%d %H:%M'),\n",
    "            'sleeping_cells': sleeping_after,\n",
    "            'total_cells': len(all_sites) * 2,\n",
    "            'baseline_avg_thp': baseline_kpis.get('avg_throughput_mbps', 0) if baseline_kpis else 0,\n",
    "            'sim1_avg_thp': sim1_kpis.get('avg_throughput_mbps', 0),\n",
    "            'sim2_avg_thp': sim2_kpis['avg_throughput_mbps'],\n",
    "            'recommendations_generated': len(recommendations),\n",
    "            'recommendations_approved': len(approved),\n",
    "        })\n",
    "        total_elapsed = time_module.time() - engine_start\n",
    "        avg_per_iter = total_elapsed / (iteration + 1)\n",
    "        remaining = avg_per_iter * (num_iterations - iteration - 1)\n",
    "        print(f\"  ✓ Iteration {iteration+1} complete — {sleeping_after} cells sleeping\")\n",
    "        print(f\"    Timing: LLM1={t_llm1:.1f}s  Sim1={t_sim1:.1f}s  LLM2={t_llm2:.1f}s  Sim2={t_sim2:.1f}s  |  Iter={iter_elapsed:.1f}s\")\n",
    "        print(f\"    Elapsed: {total_elapsed:.0f}s ({total_elapsed/60:.1f}min)  |  ETA: {remaining:.0f}s ({remaining/60:.1f}min)\")\n",
    "\n",
    "        # Write iteration to log file\n",
    "        log_file.write(f\"\\nIteration {iteration+1}/{num_iterations} | {(Tv - timedelta(minutes=15)).strftime('%H:%M UTC')} | {profile['name']}\\n\")\n",
    "        log_file.write(f\"  sleeping_cells={sleeping_after}/{len(all_sites)*2}\\n\")\n",
    "        log_file.write(f\"  baseline: avg_thp={baseline_kpis.get('avg_throughput_mbps', 0) if baseline_kpis else 0:.2f} Mbps\\n\")\n",
    "        log_file.write(f\"  sim1: avg_thp={sim1_kpis.get('avg_throughput_mbps', 0):.2f} Mbps\\n\")\n",
    "        log_file.write(f\"  sim2: avg_thp={sim2_kpis['avg_throughput_mbps']:.2f} Mbps\\n\")\n",
    "        log_file.write(f\"  timing: LLM1={t_llm1:.1f}s Sim1={t_sim1:.1f}s LLM2={t_llm2:.1f}s Sim2={t_sim2:.1f}s | Total={iter_elapsed:.1f}s\\n\")\n",
    "        log_file.flush()\n",
    "\n",
    "    total_time = time_module.time() - engine_start\n",
    "    summary_df = pd.DataFrame(loop_state.iteration_log)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CLOSED-LOOP ENGINE COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total iterations: {num_iterations}\")\n",
    "    print(f\"Final sleeping cells: {sum(1 for v in loop_state.cell_sleep_state.values() if v)}\")\n",
    "    print(f\"Total wall time: {total_time:.1f}s ({total_time/60:.1f}min)\")\n",
    "    print(f\"Avg per iteration: {total_time/max(num_iterations,1):.1f}s\")\n",
    "\n",
    "    # Energy efficiency KPI\n",
    "    compute_energy_efficiency(summary_df)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Write ITERATION SUMMARY and final table to log\n",
    "    log_file.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    log_file.write(\"ITERATION SUMMARY\\n\")\n",
    "    log_file.write(\"=\" * 80 + \"\\n\")\n",
    "    log_file.write(summary_df.to_string(index=False) + \"\\n\")\n",
    "    log_file.write(\"=\" * 80 + \"\\n\")\n",
    "    log_file.write(f\"\\nTotal iterations: {num_iterations}\\n\")\n",
    "    log_file.write(f\"Final sleeping cells: {sum(1 for v in loop_state.cell_sleep_state.values() if v)}\\n\")\n",
    "    log_file.write(f\"Total wall time: {total_time:.1f}s ({total_time/60:.1f}min)\\n\")\n",
    "    log_file.close()\n",
    "    print(f\"\\n✓ Log written to {log_path}\")\n",
    "\n",
    "    return loop_state, summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execute Closed-Loop Simulation\n",
    "\n",
    "Run the closed-loop engine: each 15-minute interval goes through LLM recommendation → RSG simulation → LLM validation → RSG confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Execution — Closed-Loop Simulation (AWS RSG default)\n",
    "# =============================================================================\n",
    "import os, json, hashlib, requests, socket\n",
    "from pathlib import Path\n",
    "from viavi.rsg import Scenario, Simulation  # noqa: F401\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def _tcp_ok(host: str, port: int = 8000, timeout: float = 5.0) -> bool:\n",
    "    try:\n",
    "        socket.create_connection((host, port), timeout=timeout).close()\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        print(f\"❌ TCP connect failed to {host}:{port}: {ex}\")\n",
    "        return False\n",
    "\n",
    "def _resolve_conf_arg(conf_name: str) -> str:\n",
    "    \"\"\"Prefer an absolute local path if the conf exists; otherwise pass through the name.\"\"\"\n",
    "    conf_name = (conf_name or \"\").strip()\n",
    "    if not conf_name:\n",
    "        return conf_name\n",
    "    p = Path(conf_name)\n",
    "    if p.exists():\n",
    "        return str(p.resolve())\n",
    "    # try relative to PROJECT_ROOT and cwd\n",
    "    for base in [Path.cwd(), PROJECT_ROOT if 'PROJECT_ROOT' in globals() else Path.cwd()]:\n",
    "        cand = base / conf_name\n",
    "        if cand.exists():\n",
    "            return str(cand.resolve())\n",
    "    # fallback: if any *.conf exists in cwd, use most recent\n",
    "    confs = sorted(Path.cwd().glob('*.conf'), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    if confs:\n",
    "        print(f\"⚠ Conf '{conf_name}' not found; using most recent conf in cwd: {confs[0].name}\")\n",
    "        return str(confs[0].resolve())\n",
    "    return conf_name\n",
    "\n",
    "def connect_rsg_and_load_scenario(rsg_host: str, user_name: str, scenario_conf: str, rsg_address_override: str = \"\"):\n",
    "    \"\"\"Connect to RSG and create a Scenario, printing actionable diagnostics on failure.\"\"\"\n",
    "    scenario_arg = _resolve_conf_arg(scenario_conf)\n",
    "\n",
    "    # If caller provides a full RSG base URL override (e.g., internal RSG), use it directly.\n",
    "    if rsg_address_override:\n",
    "        print(\"Using RSG_ADDRESS override:\", rsg_address_override)\n",
    "        return Scenario(scenario_arg, rsg_address_override)\n",
    "\n",
    "    # Network preflight\n",
    "    if not _tcp_ok(rsg_host, 8000):\n",
    "        raise RuntimeError(f\"Cannot reach RSG host {rsg_host}:8000 (network/VPN/firewall).\")\n",
    "\n",
    "    # Best-effort status\n",
    "    try:\n",
    "        s = requests.get(f\"http://{rsg_host}:8000/status\", timeout=10)\n",
    "        print(\"/status HTTP:\", s.status_code)\n",
    "        if s.ok:\n",
    "            status = s.json()\n",
    "            print(f\"RSG containers: {status.get('available_containers')}/{status.get('total_containers')}\")\n",
    "            if status.get('message'):\n",
    "                print(\"RSG message:\", status['message'])\n",
    "        else:\n",
    "            print(\"/status body:\", s.text[:500])\n",
    "    except Exception as ex:\n",
    "        print(f\"⚠ Could not query /status: {ex}\")\n",
    "\n",
    "    # Allocate a stable session per (public_ip, user_name)\n",
    "    try:\n",
    "        ip = requests.get(\"https://api.ipify.org\", timeout=5).text.strip()\n",
    "    except Exception:\n",
    "        ip = \"unknownip\"\n",
    "    h = hashlib.sha256(f\"{ip}-{user_name}\".encode()).hexdigest()[:8]\n",
    "    rsg_addr = f\"http://{rsg_host}:8000/c/{h}/\"\n",
    "    print(\"RSG addr:\", rsg_addr)\n",
    "    print(\"Scenario arg:\", scenario_arg)\n",
    "\n",
    "    try:\n",
    "        return Scenario(scenario_arg, rsg_addr)\n",
    "    except Exception as e:\n",
    "        resp = getattr(getattr(e, '__cause__', None), 'response', None)\n",
    "        if resp is not None:\n",
    "            try:\n",
    "                payload = resp.json()\n",
    "                detail = json.dumps(payload, indent=2)[:2000]\n",
    "            except Exception:\n",
    "                detail = resp.text[:2000]\n",
    "            raise RuntimeError(f\"Scenario creation failed (HTTP {resp.status_code}). Details:\\n{detail}\") from e\n",
    "        raise\n",
    "\n",
    "# Create Scenario\n",
    "scenario = connect_rsg_and_load_scenario(\n",
    "    rsg_host=RSG_HOST,\n",
    "    user_name=USER_NAME,\n",
    "    scenario_conf=SCENARIO_CONF,\n",
    "    rsg_address_override=RSG_ADDRESS,\n",
    ")\n",
    "print(\"✓ Scenario connected\")\n",
    "\n",
    "# Pre-calculate avg QoS (needed by helper functions)\n",
    "avg_qos = df.groupby(['time', 'site'])['UE_Throughput'].mean().reset_index()\n",
    "avg_qos = avg_qos.rename(columns={'UE_Throughput': 'avg_qos'})\n",
    "\n",
    "from sqlalchemy import text\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS site_avg_qos\"))\n",
    "    conn.commit()\n",
    "avg_qos.to_sql('site_avg_qos', engine, index=False, if_exists='replace')\n",
    "print(f\"✓ Pre-calculated avg QoS for {len(avg_qos)} (time, site) combinations\")\n",
    "\n",
    "# All timestamps and sites from dataset\n",
    "all_timestamps = sorted(df['time'].unique())\n",
    "all_sites = sorted(df['site'].unique())\n",
    "\n",
    "# ms_to_datetime utility\n",
    "def ms_to_datetime(ms):\n",
    "    \"\"\"Convert milliseconds timestamp to UTC datetime string.\"\"\"\n",
    "    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).strftime('%Y-%m-%d %H:%M UTC')\n",
    "\n",
    "print(f\"✓ {len(all_timestamps)} timestamps, {len(all_sites)} sites\")\n",
    "\n",
    "# ── User Configuration ──\n",
    "START_DATETIME = datetime(2023, 1, 1, 0, 0, tzinfo=timezone.utc)\n",
    "NUM_ITERATIONS = 96  # Full 24h (set to 4 for quick test = 1 hour)\n",
    "\n",
    "print(f\"\\nStarting closed-loop: {START_DATETIME.strftime('%Y-%m-%d %H:%M UTC')}, {NUM_ITERATIONS} iterations\")\n",
    "\n",
    "# ── Execute ──\n",
    "loop_state, summary_df = run_closed_loop(\n",
    "    llm=llm,\n",
    "    scenario=scenario,\n",
    "    engine=engine,\n",
    "    df_ue=df_ue,\n",
    "    df_cell=df_cell,\n",
    "    all_timestamps=all_timestamps,\n",
    "    all_sites=all_sites,\n",
    "    operator_intent=operator_intent,\n",
    "    qos_threshold=QOS_THRESHOLD,\n",
    "    start_datetime=START_DATETIME,\n",
    "    num_iterations=NUM_ITERATIONS,\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ITERATION SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Closed-Loop Results Visualization\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "\n",
    "# Traffic period colors\n",
    "_PERIODS = [\n",
    "    {\"name\": \"Night\",      \"start\": 0,  \"end\": 8,  \"color\": \"#1a237e\"},\n",
    "    {\"name\": \"Early\",    \"start\": 8,  \"end\": 9,  \"color\": \"#b71c1c\"},\n",
    "    {\"name\": \"Morning\",    \"start\": 9,  \"end\": 13, \"color\": \"#e65100\"},\n",
    "    {\"name\": \"Afternoon\",  \"start\": 13, \"end\": 18, \"color\": \"#1b5e20\"},\n",
    "    {\"name\": \"Evening_1\",    \"start\": 18, \"end\": 20, \"color\": \"#4a148c\"},\n",
    "    {\"name\": \"Evening_2\",    \"start\": 20, \"end\": 22, \"color\": \"#4a148c\"},\n",
    "    {\"name\": \"Late Night\", \"start\": 22, \"end\": 24, \"color\": \"#1a237e\"},\n",
    "]\n",
    "\n",
    "# Extract time axis from summary_df\n",
    "time_hours = []\n",
    "for t in summary_df['time_utc']:\n",
    "    dt = pd.to_datetime(t)\n",
    "    time_hours.append(dt.hour + dt.minute / 60)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n",
    "\n",
    "# ── Panel 1: Sleeping cells over time ──\n",
    "ax1.fill_between(time_hours, summary_df['sleeping_cells'], alpha=0.35, color='#1565C0')\n",
    "ax1.plot(time_hours, summary_df['sleeping_cells'], color='#0D47A1', linewidth=2)\n",
    "\n",
    "for p in _PERIODS:\n",
    "    ax1.axvspan(p['start'], p['end'], alpha=0.07, color=p['color'])\n",
    "\n",
    "ax1.axhline(y=len(all_sites), color='gray', linestyle=':', alpha=0.5)\n",
    "ax1.text(24.1, len(all_sites), f'{len(all_sites)} N1 cells', va='center', fontsize=8, color='gray')\n",
    "ax1.set_ylabel('Cells Sleeping', fontsize=10)\n",
    "ax1.set_title('Closed-Loop Energy Saving — Sleeping Cells Over Time', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.yaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "ax1.grid(axis='both', alpha=0.2, linestyle='--')\n",
    "\n",
    "# ── Panel 2: Avg throughput over time + QoS threshold ──\n",
    "ax2.plot(time_hours, summary_df['sim2_avg_thp'], color='#2E7D32', linewidth=2, label='Sim #2 Avg Throughput')\n",
    "if 'sim1_avg_thp' in summary_df.columns:\n",
    "    ax2.plot(time_hours, summary_df['sim1_avg_thp'], color='#FF9800', linewidth=1.5, alpha=0.6, label='Sim #1 Avg Throughput')\n",
    "ax2.axhline(y=QOS_THRESHOLD, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label=f'QoS Threshold ({QOS_THRESHOLD} Mbps)')\n",
    "\n",
    "for p in _PERIODS:\n",
    "    ax2.axvspan(p['start'], p['end'], alpha=0.07, color=p['color'])\n",
    "\n",
    "ax2.set_ylabel('Avg Throughput (Mbps)', fontsize=10)\n",
    "ax2.set_title('Network Throughput Over Time', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=9, loc='upper right')\n",
    "ax2.set_ylim(bottom=0)\n",
    "ax2.grid(axis='both', alpha=0.2, linestyle='--')\n",
    "\n",
    "# Period labels on ax2\n",
    "for p in _PERIODS:\n",
    "    mid = (p['start'] + p['end']) / 2\n",
    "    ax2.text(mid, 1.02, p['name'], ha='center', va='bottom', fontsize=8,\n",
    "             fontstyle='italic', color=p['color'], alpha=0.9,\n",
    "             transform=ax2.get_xaxis_transform())\n",
    "\n",
    "ax2.set_xlabel('Time of Day (UTC)', fontsize=10)\n",
    "\n",
    "# X-axis formatting\n",
    "ax2.set_xlim(0, 24)\n",
    "ax2.set_xticks(range(0, 25, 2))\n",
    "ax2.set_xticklabels([f'{h:02d}:00' for h in range(0, 25, 2)], fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "OUTPUT_DIR = str(PROJECT_ROOT / 'output')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "plt.savefig(f'{OUTPUT_DIR}/closed_loop_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary stats\n",
    "peak_sleeping = summary_df['sleeping_cells'].max()\n",
    "avg_sleeping = summary_df['sleeping_cells'].mean()\n",
    "sleeping_ratio = summary_df['sleeping_cells'].mean() / (len(all_sites) * 2)\n",
    "avg_thp = summary_df['sim2_avg_thp'].mean()\n",
    "\n",
    "print(f\"\\nClosed-Loop Summary:\")\n",
    "print(f\"  Peak cells sleeping: {peak_sleeping}/{len(all_sites)} N1 cells\")\n",
    "print(f\"  Avg cells sleeping: {avg_sleeping}/{len(all_sites)} N1 cells\")\n",
    "print(f\"  Average throughput (Sim #2): {avg_thp:.2f} Mbps\")\n",
    "print(f\"  Approx sleeping/total ratio: {sleeping_ratio:.2f} ({sleeping_ratio*100:.0f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ES Blueprint (Python 3.12)",
   "language": "python",
   "name": "es-blueprint-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
